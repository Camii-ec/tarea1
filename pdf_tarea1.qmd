---
title: "Tarea 1"
subtitle: "EYP3907 - Series de Tiempo"
format: 
  pdf: 
    include-in-header: 
      text: |
        \usepackage{amsmath}
    colorlinks: true
    geometry:
      - top=20mm
      - left=20mm
      - right=20mm
      - heightrounded
    fig-pos: H
    classoption: twocolumn
author: 
  - name: "Sebastián Celaya"
  - name: "Camila Echeverría"
  - name: "Francisca Vilca"
crossref:
  fig-title: Figura
  fig-prefix: Figura
  tbl-title: Tabla
  tbl-prefix: Tabla
tbl-cap-location: bottom
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = F, warning = F)

# Paquetes
library(tidyverse)
library(dplyr)
library(lubridate) # por el año
library(patchwork)
# library(kableExtra)
# Analisis de la serie de tiempo
library(lmtest)
library(forecast)

## Funciones 
source("TS.diag.R")
source("summary.arima.R")
source("salida.arima.R")

# Carga de datos
data <- rio::import("datos_970410_231003.csv")

df <- janitor::clean_names(data)
```


## Introducción 

En esta tarea, utilizaremos los datos mensuales de concentración de monóxido de carbono (CO), recopilados en la estación de monitores de Pudahuel, para ajustar un modelo de regresión que nos permita predecir la concentración de este contaminante a lo largo del tiempo. 


```{r echo=FALSE}
# Ponemos el formato de las fechas
df$fecha_yymmdd = as.Date(
  # para los que son 00 0X 01
  ifelse(df$fecha_yymmdd < 1000, 
         paste0("000", df$fecha_yymmdd),
         # para los 3 que son 00 1X 01
         ifelse(df$fecha_yymmdd < 2000, 
                paste0("00", df$fecha_yymmdd),
                # Para los que son 0X XX 01
                ifelse(df$fecha_yymmdd < 100000, 
                       paste0("0", df$fecha_yymmdd),
                       as.character(df$fecha_yymmdd)))),
  format = "%y%m%d"
)

# Analizaremos el monoxido de carbono
df$co <- ifelse(
  df$registros_validados != "",
  # Primero los registros válidos
  df$registros_validados,
  ifelse(
    !is.na(df$registros_preliminares),
    # Segundo los registros preliminares
    df$registros_preliminares,
    # Tercero los registros no válidos
    df$registros_no_validados
  )
)

# Declaramos de donde vienen los datos
# por qué? pues porque si
df$tipo_registro = ifelse(
  df$registros_validados != "",
  # Primero los registros válidos
  "Registro válido",
  ifelse(
    !is.na(df$registros_preliminares),
    # Segundo los registros preliminares
    "Registro preliminar",
    # Tercero los registros no válidos
    "Registro no válido"
  )
)

# Declaramos los datos que usaremos en la construcción del modelo
# y los datos que se ocuparán en la validación
df$uso =ifelse(df$fecha_yymmdd < as.Date("2022-12-31"),
               "Entrenamiento",
               "Validación")

df$co <- as.numeric(gsub(",", ".", df$co))
train <- df %>% 
  filter(uso == "Entrenamiento")

Xt <- na.omit(train$co)
Xt <- ts(Xt, start = c(1997,5), frequency = 12)
t <- as.numeric(time(Xt))
```


## Análisis Exploratorio

Los niveles de Monóxido de Carbono (CO) registrados en Pudahuel presentan los siguientes valores:

```{r, fig.width = 10, fig.height = 8}
# Graficos de series de tiempo
time_serie = train %>% 
  ggplot(aes(x = fecha_yymmdd, y = co)) +
  geom_line(color = "#808080", size = 0.8) +  
  labs(title = "Variación del Monóxido de Carbono en ppm en Estación Pudahuel",
       subtitle = "Registros válidos desde mayo de 1997 a diciembre del 2022",
       caption = "Datos otorgados por Ministerio del Medio Ambiente de Chile",
       x = "Fecha", y = "Valor") +
  scale_x_date(date_breaks = "2 year", date_labels = "%Y") +
  theme_bw() +
  theme(plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        plot.subtitle = element_text(size = 9,
                                     #face = "bold",
                                     color = "black",
                                     hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))


# Boxplot de los datos  Esta bonito, a ponerlo
box_plot = df %>%
  ggplot(aes(x = co, y = 0)) +
  # geom_violin(color = "purple3") +
  geom_boxplot(fill = "#808080",
               width = 0.3) +
  ylim(c(-0.5, 0.5)) +
  theme_bw() +
  xlab("CO ppm") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        plot.subtitle = element_text(size = 9,
                                     #face = "bold",
                                     color = "black",
                                     hjust = 0.5),
        axis.title.x = element_text(size = 8)) +
  labs(title = "Boxplot de Monóxido de Carbono",
       subtitle = "Medida en Pudahuel")

time_serie / box_plot
```

Del gráfico anterior se puede ver que la mitad de los datos presenta un nivel de CO cercano al $0.5$ y la otra mitad tiene un rango de valores mucho mayor. De igual forma se aprecia que los datos presentan una gran varianza. 

Luego, si evaluamos los gráficos de autocorrelación y autocorrelación parcial de los datos presentados anteriormente, es claro notar que estos presentan una alta estacionalidad y correlación, a través del tiempo, tal como se observa a continuación:

```{r}
# ACF base
acf <- acf(Xt, plot = FALSE)
acf_data <- data.frame(Lag = acf$lag,
                       ACF = acf$acf)

# PACF base
pacf <- pacf(Xt, plot = FALSE)
pacf_data <- data.frame(Lag = pacf$lag,
                        PACF = pacf$acf)

n = nrow(df)
```

```{r, fig.width = 10, fig.height = 8}
ACF = ggplot(acf_data, aes(x = Lag, y = ACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF",
       title = "Gráfico de Autocorrelación de los datos") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))

PACF = pacf_data %>%
  ggplot(aes(x = Lag, y = PACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF",
       title = "Gráfico de Autocorrelación Parcial de los datos") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  #face = "bold",
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))

(ACF / PACF)
```


## Ajuste del modelo

Como se pudo ver en el gráfico de autocorrelación, presentamos estacionalidad en los datos. Es por esto que utilizaremos la transformación de box-cox en los ajustes propuestos:

### Ajuste modelo de regresión lineal con dummies

```{r}
#| echo: false
#| results: hide

junio <- na.omit(subset(df, format(fecha_yymmdd, "%m") == "06")$co)
julio <- na.omit(subset(df, format(fecha_yymmdd, "%m") == "07")$co)


df_train <- df %>%
  filter(uso == "Entrenamiento") %>% 
  select(-uso) 

df_train <- df_train[df_train$fecha_yymmdd >= as.Date("1997-12-31"),]

xt_train <- ts(df_train$co, start = c(1998, 1), frequency = 12)
xt_train[is.na(xt_train)] <- c(mean(junio), mean(julio))

t_train <- c(time(xt_train))


df_test <- df %>% 
  filter(uso == "Validación") %>% 
  select(-uso) 

xt_test <- ts(df_test$co, start = c(2023, 1), end = c(2023, 9), frequency = 12)

t_test <- c(time(xt_test))

D <- rep(1:12, 25)

train <- data.frame(x = xt_train, t = t_train, D = as.factor(D))
test <- data.frame(x = xt_test, t = t_test, D = as.factor(1:9))

mod <- lm(x ~ t*(D), data = train)
a <- MASS::boxcox(mod, plotit = FALSE)
lambda <- a$x[which.max(a$y)]

xt_train2.0 <- (xt_train^lambda - 1)/lambda
xt_test2.0 <- (xt_test^lambda - 1)/lambda

train2.0 <- data.frame(x = xt_train2.0, t = t_train, D = as.factor(D))
test2.0 <- data.frame(x = xt_test2.0, t = t_test, D = as.factor(1:9))

mod <- lm(x ~ t*(D), data = train2.0) # Interacciones significativas

pred <- forecast(mod, newdata = test2.0)
pred_box <- (pred$mean*lambda+1)^(1/lambda)
```


Al tener un período de estacionalidad igual a 12, ajustaremos un modelo regresión lineal con 12 variables dummies. Consideramos, además, la transformación de box-cox utilizando $\lambda=0.22$ para este modelo. Así, podemos obtener las siguientes conclusiones:

- Con un valor-p de 0.01, el modelo rechaza los test de normalidad.

- Por otro lado, con un valor-p de 0.12, el test de Breusch-Pagan no rechaza la homocedasticidad, por lo que podemos concluir que el modelo presenta residuos con varianza constante.

- Si se revisa el gráfico de Box-Ljung, es claro notar que se rechaza el test de blancura, por lo que se concluye que los datos podrían provenir de un ruido blanco.

```{r fig.width = 10, fig.height = 4}
#| echo: false
#| results: hide
Box.Ljung.Test(mod$residuals)
axis(1, 0:22)
```

Luego, si vemos los gráficos de autocorrelación y autocorrelación parcial de los residuos, vemos que aun existen patrones de estacionalidad.

```{r fig.width = 10, fig.height = 8}
#| echo: false
#| results: hide

acf_res <- acf(mod$residuals, plot = FALSE)
acf_data1 <- data.frame(Lag = acf_res$lag, ACF = acf_res$acf)



pacf_res <- pacf(mod$residuals, plot = FALSE)
pacf_data1 <- data.frame(Lag = pacf_res$lag, PACF = pacf_res$acf)

n = length(xt_train)

acf1 = ggplot(acf_data1, aes(x = Lag, y = ACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF",
       title = "Autocorrelación para los residuos del modelo de regresión") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  face = "bold", # Titulo en negrita
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))

pacf1 = pacf_data1 %>%
  ggplot(aes(x = Lag, y = PACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "PACF",
       title = "Autocorrelación Parcial para los residuos del modelo de regresión") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  face = "bold", # Titulo en negrita
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))+
  scale_y_continuous(limits = c(-0.8,0.8))

(acf1 / pacf1)
```

De esta manera, se puede apreciar que el modelo que sugiere esta estructura de correlación corresponde a un ARMA(2,4).

### Ajuste con función `auto.arima()`

En base a las conclusiones obtenidas anteriormente, utilizaremos la función `auto.arima()` de la librería forecast para ajustar un modelo ARMA(2,4) a los datos. 

```{r echo = FALSE}
Xt <- ts(xt_train, start = c(1998), frequency = 12)
t <- as.numeric(time(Xt))
lambda2 <- forecast::BoxCox.lambda(Xt, method = "guerrero")
fit <- forecast::auto.arima(Xt,start.p = 2,start.q = 4, lambda = lambda2)

# ACF
acf_residuals <- acf(fit$residuals, plot = FALSE)
acf_data <- data.frame(Lag = acf_residuals$lag, ACF = acf_residuals$acf)

# PACF
pacf_residuals <- pacf(fit$residuals, plot = FALSE)
pacf_data <- data.frame(Lag = pacf_residuals$lag, PACF = pacf_residuals$acf)

n = length(xt_train)
```

Al utilizar la función especificando los parámetros de un modelo ARMA(2,4), se recomienda el uso de un modelo AR(1) para explicar de mejor manera la estacionaridad de los datos. Así, las conclusiones obtenidas son las siguientes:

- Los residuos son homocedásticos, ya que el test de Breusch-Pagan no se rechaza a un nivel de confianza de $1\%$, pues el valor-p asociado es de $0.12$

- Si se revisa el gráfico de Box-Ljung, es claro notar que no se rechaza el test de blancura, pues a pesar de tener datos muy cercanos a la banda de confianza ninguno esta por debajo de la misma, por lo que se concluye que los datos no provienen de un ruido blanco.

```{r fig.width = 10, fig.height = 4}
#| echo: false
#| results: hide
Box.Ljung.Test(fit$residuals)
axis(1, 0:22)
```

- Tambien, es posible observar que los residuos no presentan autocorrelación serial, tal como se muestra a continuación

```{r, fig.width = 10, fig.height = 8}
acf = ggplot(acf_data, aes(x = Lag, y = ACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "ACF",
       title = "Gráfico de Autocorrelación para los residuos del modelo AR(1)") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  face = "bold", # Titulo en negrita
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))

pacf = pacf_data %>%
  ggplot(aes(x = Lag, y = PACF)) +
  geom_hline(yintercept = 0,
             linetype = "dashed") + 
  geom_hline(yintercept = 1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_hline(yintercept = -1.96/sqrt(n),
             linetype = "dashed",
             col = "blue") + 
  geom_segment(aes(xend = Lag,
                   yend = 0),
               color = "purple",
               size = 1) + # Líneas verticales
  geom_point(size = 2.5,
             shape = 21,
             fill = "purple") + # Puntos de color en el extremo de las líneas
  labs(x = "Lag",
       y = "PACF",
       title = "Gráfico de Autocorrelación Parcial para los residuos del modelo AR(1)") +
  theme_bw() +
  theme(axis.text.y = element_text(size = 8),
        # axis.ticks.y = element_blank(),
        axis.title.y = element_text(size = 8),
        plot.title = element_text(size = 10,
                                  face = "bold", # Titulo en negrita
                                  color = "black",
                                  hjust = 0.5),
        axis.title.x = element_text(size = 8),
        axis.text.x = element_text(size = 8))+
  scale_y_continuous(limits = c(-0.8,0.8))

(acf / pacf)
```

- A pesar de que el modelo creado es bueno en muchos sentidos, el valor-p del test de Kolmogorov-Smirnov es mucho menor a 0.05, lo que nos indica que los residuos rechazan la hipótesis nula de normalidad.

### Comparación de los modelos

Para poder probar ambos modelos ajustados, utilizaremos los datos de testeo para generar predicciones desde enero hasta septiembre del 2023. Estos resultados se presentan en la siguiente tabla:

```{r echo=FALSE}
predicciones_validacion <- forecast(fit, newdata = t_test, h = 9)
```



\begin{table}[H]
\centering
\begin{tabular}{| c | c | c | c |}
\toprule
Mes & Valor Real & Regresión & ARMA(4,2) \\
\hline
Enero & 0.37 & 0.35 & 0.32  \\
\hline
Febrero  & 0.57 & 0.33 & 0.33 \\
\hline
Marzo & 0.56 & 0.39 & 0.44  \\
\hline
Abril & 0.66 & 0.60 & 0.75  \\
\hline
Mayo & 1.17 & 0.94 & 1.21  \\
\hline
Junio & 1.53 & 1.44 & 1.63  \\
\hline
Julio & 1.47 & 1.41 & 1.64  \\
\hline
Agosto & 0.98 & 0.90 & 0.99  \\
\hline
Septiembre & 0.73 & 0.57 & 0.61  \\
\bottomrule
\end{tabular}
\caption{Comparación de predicciones}
\label{tab:cuartiles}
\end{table}

Ambos modelos generan predicciones bastante cercanas a los valores reales para los meses correspondientes. Para complementar esto, en la siguiente tabla compararemos algunas medidas de calidad de ajuste:

\begin{table}[H]
\centering
\begin{tabular}{| c | c | c | c | c | c |}
\hline
 & RMSE & MAE & MAPE \\
\hline
Regresión Lineal & 0.15 & 0.12 & 16.35\\
\hline
Modelo AR(1) & 0.23 & 0.14 & 17.00 \\
\bottomrule
\end{tabular}
\caption{Medidas de calidad de ajuste}
\label{tab:cuartiles}
\end{table}

## Conclusión 

A pesar de que el modelo de regresión lineal pareciera tener un mejor desempeño en base a las medidas de calidad de ajuste, no podemos olvidar que no cumple con el supuesto de normalidad y que posee autocorrelación serial, por lo que el modelo ARMA(2,4) representa un mejor ajuste para nuestros datos.

